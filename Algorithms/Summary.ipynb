{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "import nltk\n",
    "import json\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "from nltk.corpus import brown, stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = {}\n",
    "f = open('../glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./embeddings/embeddings.pkl', 'rb') as handle:\n",
    "    word_embeddings = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('../sermons/Charge that to my account.txt', \"r\")\n",
    "cttma = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(doc):\n",
    "    stemmed_doc = ''\n",
    "    for w in doc.split(' '):\n",
    "        stemmed_doc += stemmer.stem(w) + ' '\n",
    "    return stemmed_doc\n",
    "def remove_stopwords(sen):\n",
    "    stop_words = stopwords.words('english')\n",
    "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
    "    return sen_new\n",
    "def remove_symbols(doc):\n",
    "    cleaned_doc = []\n",
    "    punctuation = ['.', '..', '...', '?', ':', '!', ',', '\\'', ';', '``']\n",
    "    for word in doc:\n",
    "        if word not in punctuation: \n",
    "            cleaned_doc.append( re.sub(r\"[,.\\'?!]\", \"\", word))\n",
    "    return cleaned_doc\n",
    "def clean_doc(doc):\n",
    "    words = re.sub(r'\\'', '', doc).lower()\n",
    "    words = word_tokenize(re.sub(r'\\.(?=[^ \\W\\d])', '. ', words))\n",
    "    words = remove_symbols(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measurements_of_the_Heart.json\n",
      "Memorial_Service_for_Bea_Campbell.json\n",
      "Memorial_Service_for_Heather_Gillian.json\n",
      "Memorial_Service_for_Robert_Huizenga.json\n",
      "Messiahs_Community.json\n",
      "Mind_Renewal.json\n",
      "Modern_Golden_Calves.json\n",
      "Obedience_at_the_Burning_Bush.json\n",
      "Preaching_that_Reaches_the_Heart.json\n",
      "Recognizing_Divine_Interruptions.json\n",
      "Regaining_Lost_Joy.json\n",
      "Release_Resentment.json\n",
      "Renouncing_Bitterness.json\n",
      "Right_on_the_Money.json\n",
      "Right_Smack_in_the_Middle_of_Sin.json\n",
      "Room_to_Breathe.json\n",
      "Setting_the_Record_Crooked.json\n",
      "Songs_of_Our_Tears.json\n",
      "Speed_Dial.json\n",
      "Spiritual_Growth__My_Job_or_Gods_.json\n",
      "Starting_Over.json\n",
      "Strong_Grace_Hard_Word_Good_Memories.json\n",
      "Suffering.json\n",
      "The_Audacity_to_Hope.json\n",
      "The_Breath_of_God.json\n",
      "The_Critical_Transaction.json\n",
      "The_Forgiveness_Factor.json\n",
      "The_Future_and_Forgetting.json\n",
      "The_Good_News_Is_the_Bad_News_Is_Wrong.json\n",
      "The_Greater_Glory.json\n",
      "The_Journey_to_Integrity.json\n",
      "The_King_Whose_Scepter_is_a_Towel.json\n",
      "The_Most_Neglected_Commandment_in_the_Bible.json\n",
      "The_Muchness_of_God.json\n",
      "The_Neglected_Joseph_Davidson.json\n",
      "The_Principles_of_Prosperity.json\n",
      "The_Sermon_on_the_Amount.json\n",
      "The_Shortest_Distance_Between_Two_Points_is_a_Zig_Zag.json\n",
      "The_Testimony_of_a_Tax_Collector.json\n",
      "The_Ultimate_Community.json\n",
      "The_UptotheMinute_Relevance_of_the_Resurrection.json\n",
      "The_Whats_and_the_Why_of_Worship.json\n",
      "The_Whys_Have_No_Answer.json\n",
      "Tide_Riding.json\n",
      "Tragedy_and_the_Providence_of_God.json\n",
      "Trinity__The_Christian_Name_for_God.json\n",
      "Unlistened_to_Lessons_of_Life.json\n",
      "Using_Scriptures_in_Our_Lives.json\n",
      "Victory_for_Us.json\n",
      "Walking_Into_the_Purposes_of_God.json\n",
      "Whats_Driving_You_.json\n",
      "Whats_Holding_You_Back_.json\n",
      "What_a_Nation_Should_Never_Forget.json\n",
      "What_to_Do_with_Trouble.json\n",
      "When_Good_Snakes_Become_Bad_Snakes.json\n",
      "When_Teens_Rebel.json\n",
      "When_the_Roll_is_Called_Down_Here.json\n",
      "When_To_Flee.json\n",
      "Who_Cares_.json\n",
      "Why_Are_You_So_Angry_.json\n",
      "Worship__What_Were_Doing__Why.json\n",
      "Yes_Yes_and_No_No.json\n",
      "Yet_Will_I_Praise_Thee.json\n",
      "You_Shall_Not_Kill.json\n",
      "Zaccheus.json\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for sermon in os.listdir('../sermons/preachingtoday'):\n",
    "    f=open('../sermons/preachingtoday/'+ sermon, 'rb')\n",
    "    contents =f.read()\n",
    "    contents = json.loads(contents)\n",
    "    if not contents['summary']:\n",
    "        summary = clean_and_send(contents[\"text\"])\n",
    "        contents['summary'] = summary\n",
    "        print(sermon)\n",
    "        doc = json.dumps(contents)\n",
    "        filename = '../sermons/preachingtoday/' + sermon\n",
    "        with open(filename,'w') as f:\n",
    "            f.write(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_send(doc):\n",
    "    regex = re.compile('[^a-zA-Z0-9.?!\\-: ]')\n",
    "    doc = re.sub(r'[^a-zA-Z0-9.?!\\-: ]', '' ,doc)\n",
    "    doc = re.sub(r'\\.(?=[^ \\W\\d])', '. ', doc)\n",
    "\n",
    "    og_sentences = sent_tokenize(doc)\n",
    "    sentences = sent_tokenize(doc)\n",
    "    if len(sentences)< 9:\n",
    "        return doc\n",
    "    else:\n",
    "        return summarize(sentences, og_sentences)\n",
    "    \n",
    "def summarize(sentences, og_sentences):\n",
    "    # remove punctuations, numbers and special characters\n",
    "    clean_sentences = pd.Series(sentences).str.replace(\"[^a-zA-Z]\", \" \")\n",
    "    # make alphabets lowercase\n",
    "    clean_sentences = [s.lower() for s in clean_sentences]\n",
    "    # remove stopwords from the sentences\n",
    "    clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]\n",
    "    sentence_vectors = []\n",
    "    for i in clean_sentences:\n",
    "        if len(i) != 0:\n",
    "            v = sum([word_embeddings.get(w, np.zeros((128,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "        else:\n",
    "            v = np.zeros((128,))\n",
    "        sentence_vectors.append(v)\n",
    "    # similarity matrix\n",
    "    sim_mat = np.zeros([len(sentences), len(sentences)])\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences)):\n",
    "            if i != j:\n",
    "                sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,128), sentence_vectors[j].reshape(1,128))[0,0]\n",
    "    nx_graph = nx.from_numpy_array(sim_mat)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(og_sentences)), reverse=True)\n",
    "    summary = ''\n",
    "    for i in range(7):\n",
    "        summary += ' ' + ranked_sentences[i][1]\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -->  And eventually after a couple of weeks of travel that probably felt like years Onesimus and Tychicus arrive in Colossae and Onesimus comes face to face with Philemon and hes probably terrified but he has this letter and it would be sealed with Pauls personal seal and its signed in Pauls hand so that Philemon would know its the real deal.\n",
      "1 -->  I thank my God always when I remember you in my prayers because I hear of your love and of the faith that you have toward the Lord Jesus and for all the saints and I pray that the sharing of your faith may become effective for the full knowledge of every good thing that is in us for the sake of Christ.\n",
      "2 -->  But they would likely have been slaves so to become a bishop seems unlikely... it makes sense that it might be our Onesimus the one who spent significant time with Paul during his imprisonment in Rome who would have gone back to Paul in Rome if Philemon received his letter and did the more than Paul even asked.\n",
      "3 -->  So its one thing to cover a dinner but its another thing to pay off someones debt owed due to reckless spending no ones jumping up to say charge that to my account...Except that you parents out there youre thinking that you might... right?\n",
      "4 -->  2 Cor 32 And just like Paul would have set his seal into the letter so that the recipient would know it was from him Jesus seals us with the Spirit just like it says in Ephesians In him you also when you heard the word of truth the gospel of your salvation and believed in him were sealed with the promised Holy Spirit Eph 113.\n",
      "5 -->  It made me think too that in the bible it sometimes happened that you would meet God and God would change your name to reflect your new life because youre changed one way or another when you meet him.\n",
      "6 -->  Throughout the Bible and maybe especially in Philemon God shows us what it means to be willing to take on the debt of another to be willing and ready to say charge that to my account.\n"
     ]
    }
   ],
   "source": [
    "nx_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(nx_graph)\n",
    "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(og_sentences)), reverse=True)\n",
    "for i in range(7):\n",
    "    print(i, '--> ',ranked_sentences[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
